import asyncio
from openai import OpenAI
from fastapi import FastAPI, HTTPException
from starlette import status
import uvicorn
from pydantic import BaseModel, Field
from typing import Literal
import os
import logging

API_KEY = os.getenv('API_KEY')
tori_assistant_id = os.getenv('tori_assistant_id')

client = OpenAI(
    api_key=API_KEY,
    project='proj_YA4wA5gFbCTSd8ImZ1UapNJN'
)
app = FastAPI()

# ë¡œê¹… ì„¤ì • (ì‹œê°„ ì œê±°)
logging.basicConfig(
    level=logging.DEBUG,
    format="%(levelname)s - %(message)s"
)
logger = logging.getLogger("fastapi-logger")

# OpenAI ë° HTTP ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ìˆ˜ì¤€ ì¡°ì •
logging.getLogger("httpcore").setLevel(logging.INFO)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("uvicorn").setLevel(logging.WARNING)
logging.getLogger("uvicorn.access").setLevel(logging.WARNING)


class FirstRequestModel(BaseModel):
    first_prompt: str = Field(..., min_length=1, description='Input first_assistant_prompt')

    model_config = {
        "json_schema_extra": {
            'example': {
                'first_prompt': 'ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë• ì–´?ğŸ˜€'
            }
        }
    }


class ThreadIdResponseModel(BaseModel):
    new_threadId: str


async def createMessageInThread(threadId: str, role: str, content: str):
    await asyncio.to_thread(
        client.beta.threads.messages.create,
        thread_id=threadId,
        role=role,
        content=content
    )


@app.post(
    "/set_and_get_new_threadId",
    status_code=status.HTTP_201_CREATED,
    response_model=ThreadIdResponseModel,
    responses={
        500: {
            "description": "Internal Server Error",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Thread creation failed due to Internal Server Error, <Error Explanation>"
                    }
                }
            }
        },
        503: {
            "description": "Service Unavailable",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Thread setup failed due to Service Unavailable, <Error Explanation>"
                    }
                }
            }
        }
    }
)
async def makeThreadId(firstRequest: FirstRequestModel) -> ThreadIdResponseModel:
    '''client requestê°€ ìˆìœ¼ë©´ ìƒˆë¡œìš´ ì“°ë ˆë“œë¥¼ ë§Œë“¤ê³  ì´ˆê¸° ì„¸íŒ…ì„ í•œ ë’¤ í•´ë‹¹ thread_idë¥¼ return í•˜ëŠ” í•¨ìˆ˜'''
    try:
        empty_thread = await asyncio.to_thread(client.beta.threads.create)
        new_thread_id = empty_thread.id
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f'The thread has not been created due to Internal Server Error, {e}'
        )

    try:
        await createMessageInThread(
            threadId=new_thread_id,
            role="user",
            content='(ëŒ€í™”ì‹œì‘)'
        )
        await createMessageInThread(
            threadId=new_thread_id,
            role="assistant",
            content=firstRequest.first_prompt
        )
        return ThreadIdResponseModel(new_threadId=new_thread_id)

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f'The thread setting has not been successfuly completed due to Internal Server Error, {e}'
        )


class MessageModel(BaseModel):
    thread_id: str = Field(..., min_length=1, description="Input user's thread_id")
    new_user_message: str = Field(..., min_length=1, description="Input user prompt")

    model_config = {
        "json_schema_extra": {
            "example": {
                "thread_id": "thread_ysvw3IGw9WH2NgGtas8qvNdX",
                "new_user_message": "ì˜¤ëŠ˜ì€ ì¢‹ì€ í•˜ë£¨ì˜€ì–´",
            }
        }
    }


class ToriResponseModel(BaseModel):
    tori_message: str


async def createRun(thread_id: str, assistant_id: str):
    return await asyncio.to_thread(
        client.beta.threads.runs.create,
        thread_id=thread_id,
        assistant_id=assistant_id
    )


async def retrieveRun(thread_id: str, run_id: str):
    return await asyncio.to_thread(
        client.beta.threads.runs.retrieve,
        thread_id=thread_id,
        run_id=run_id
    )


@app.post(
    "/retrieve_tori_message",
    status_code=status.HTTP_201_CREATED,
    response_model=ToriResponseModel,
    responses={
        404: {
            "description": "Failed to CreateMessageInThread",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Failed to CreateMessageInThread, <Error Explanation>"
                    }
                }
            },
        },
        500: {
            "description": "Internal Server Error",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Failed to <Failed Job>, <Error Explanation>"
                    }
                }
            },
        },
    },
)
async def getMessageFromTori(model: MessageModel) -> ToriResponseModel:
    thread_id = model.thread_id
    user_prompt = model.new_user_message

    logger.info("Starting process to retrieve Tori message.")
    logger.debug(f"Thread ID: {thread_id}, User Prompt: {user_prompt}")

    try:
        await createMessageInThread(
            threadId=thread_id,
            role="user",
            content=user_prompt,
        )
    except Exception as e:
        logger.error(f"Failed to CreateMessageInThread: {e}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Failed to CreateMessageInThread, {e}",
        )

    try:
        run = await createRun(thread_id=thread_id, assistant_id=tori_assistant_id)
        run_id = run.id
    except Exception as e:
        logger.error(f"Failed to CreateRun: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to CreateRun, {e}",
        )

    timeout = asyncio.get_event_loop().time() + 15  # 15 seconds timeout

    while True:
        try:
            retrieve_run = await retrieveRun(thread_id=thread_id, run_id=run_id)
        except Exception as e:
            logger.error(f"Failed to RetrieveRun: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Failed to RetrieveRun, {e}",
            )

        if retrieve_run.status == "completed":
            logger.info("Run completed successfully. Retrieving messages.")
            thread_messages = await asyncio.to_thread(
                client.beta.threads.messages.list,
                thread_id
            )
            tori_message = thread_messages.data[0].content[0].text.value
            return ToriResponseModel(tori_message=tori_message)

        elif retrieve_run.status in ["queued", "in_progress"]:
            logger.debug("Run is in progress. Retrying...")
            await asyncio.sleep(0.5)
        else:
            logger.error(
                f"Failed to get completed status from Run and got {retrieve_run.status}, {Exception}"
            )
            return ToriResponseModel(
                tori_message="(í† ë¦¬ê°€ ì ê¹ ë”´ ìƒê°ì„ í–ˆë‚˜ë´ìš”! ë‹¤ì‹œ í•œë²ˆ í† ë¦¬ë¥¼ ë¶ˆëŸ¬ì£¼ì„¸ìš” ã…œã…œ)"
            )

        if asyncio.get_event_loop().time() > timeout:
            logger.error("Timeout while waiting for the run to complete.")
            return ToriResponseModel(
                tori_message="(í† ë¦¬ê°€ ì ê¹ ë”´ ìƒê°ì„ í–ˆë‚˜ë´ìš”! ë‹¤ì‹œ í•œë²ˆ í† ë¦¬ë¥¼ ë¶ˆëŸ¬ì£¼ì„¸ìš” ã…œã…œ)"
            )


system_prompt = '''
#ì§€ì‹œë¬¸
ë„ˆëŠ” 'AIì™€ì˜ ëŒ€í™”ë¥¼ í†µí•´ í•˜ë£¨ë¥¼ ê¸°ë¡'í•œ 'ìœ ì €'ì˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì´ 'ìœ ì €'ì˜ ì…ì¥ì—ì„œ ìì‹ ì˜ í•˜ë£¨ë¥¼ ì •ë¦¬í•´ì£¼ëŠ” ì¹œê·¼í•œ ëŠë‚Œì˜ í•˜ë£¨ì¼ê¸° ì •ë¦¬ ë„ìš°ë¯¸ì•¼. ì•„ë˜ì˜ ì œì•½ì‚¬í•­ì„ ì˜ ë³´ê³  ì •ë¦¬í•´ì¤˜.
#ì œì•½ì‚¬í•­
1. í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½(ì£¼ì œê°€ ì—¬ëŸ¬ ê°œë©´ ì—¬ëŸ¬ ê°œì˜ ìš”ì•½ì´ ë‚˜ì˜´)
2. ê°ì •ì´ë‚˜ ëŠë‚Œì„ ê¸°ë¡ì„ í•œ ê²½ìš°, **í•´ë‹¹ ê°ì •ì´ë‚˜ ëŠë‚Œì„ ë°˜ë“œì‹œ í•´ë‹¹ ê¸°ë¡**ì— í¬í•¨í• ê²ƒ ex) ë²„ìŠ¤ì—ì„œ í• ì•„ë²„ì§€ ë•Œë¬¸ì— ìŠ¬íë˜ ë‚ 
3. summaryì˜ ì²« contentëŠ” '~~í•œ ë‚ ', '~~í•œ í•˜ë£¨'ì™€ ê°™ì´ ë§ˆë¬´ë¦¬í•´ì„œ ìš”ì•½
4. summaryì˜ ë‘ë²ˆì§¸ contentë¶€í„°ëŠ” ë°˜ë“œì‹œ **ëª…ì‚¬í˜• ì–´ë¯¸ '-ã…','ìŒ'** ë˜ëŠ” ëª…ì‚¬(ê°€ë”)ë¥¼ ë‹¤ì–‘í•˜ê²Œ ë²ˆê°ˆì•„ ì‚¬ìš©í•´ê°€ë©´ì„œ ë¬¸ì¥ì„ ë§ˆë¬´ë¦¬í•˜ëŠ” í˜•ì‹ì„ ì§€ì¼œì¤˜
5. AIì˜ ëŒ€í™”ëŠ” ê¸°ë¡ ìš”ì•½ìœ¼ë¡œ ë„£ì§€ ì•ŠëŠ”ë‹¤. ì˜¨ì „íˆ ì‚¬ìš©ìì˜ ëŒ€í™”ë§Œ ìš”ì•½í•´
6. markdownë¬¸ë²•ì€ ì“°ì§€ë§ˆ
#ì˜ˆì‹œ
[ì˜ˆì‹œ1]
{
  "dotori_emotion": "happy",
  "summary": [
    {
      "content": "ì†ë‹˜ì´ ë§ì•„ì„œ ë°”ë¹´ë˜ ì¹´í˜ì—ì„œ ì¼í•œ ë‚ "
    },
    {
      "content": "ì¡°ê¸ˆ í˜ë“¤ê¸´ í–ˆì§€ë§Œ ê¸°ë¶„ì€ ì¢‹ì•˜ìŒ." 
    },
    {
      "content": "ë‚´ì¼ë„ ì¹´í˜ì—ì„œ ì¼í•  ì˜ˆì •ì´ê³  ê¸°ëŒ€ë¨"
    },
    {
      "content": "ì§‘ì— ëŒì•„ê°€ì„œ ì‹¬ë¦¬í•™ ê´€ë ¨ ì±…ì„ ì½ìœ¼ë©° í•˜ë£¨ë¥¼ ì •ë¦¬í•  ì˜ˆì •."
    },
    {
      "content": "ì½ê³  ìˆëŠ” ì±…ì€ ì‚¬ëŒì˜ í–‰ë™ê³¼ ê°ì •ì— ëŒ€í•œ ë‚´ìš©, ì¬ë°Œê³  ìƒê°í•  ê±°ë¦¬ë„ ë§ì•˜ìŒ."
    },
    {
      "content": "ë‹¤ìŒì—ëŠ” ì†Œì„¤ì„ ì½ê³  ì‹¶ìŒ."
    }
  ]
}
'''


class SummaryLine(BaseModel):
    content: str = Field(..., description='One of the lines in the Summary')


class SummaryModel(BaseModel):
    dotori_emotion: Literal['very_happy', 'happy', 'neutral', 'sad', 'very sad', 'angry']
    summary: list[SummaryLine] = Field(description='Only summarize what has been spoken by the user')


class Prompt(BaseModel):
    role: Literal['system', 'user', 'assistant'] = Field(
        ...,
        description='Input the prompt\'s owner. Only type one of the followings [system, user, assistant]'
    )
    content: str = Field(
        ...,
        min_length=1,
        description='Input prompt generated by \'role\' '
    )


class ConversationModel(BaseModel):
    messages: list[Prompt]

    model_config = {
        "json_schema_extra": {
            'example': {
                "messages": [
                    {
                        "role": "user",
                        "content": "ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ê·¸ëƒ¥ ê·¸ë¬ë˜ê±° ê°™ì•„"
                    },
                    {
                        "role": "assistant",
                        "content": "ê·¸ë˜? ë¬´ìŠ¨ ì¼ ìˆì—ˆëŠ”ë°..?"
                    },
                    {
                        "role": "user",
                        "content": "ì½”ë”©í•˜ê³  ë°¥ë¨¹ê³  ì½”ë”©í•˜ê³ ì˜ ë°˜ë³µì´ì—ˆì–´"
                    },
                    {
                        "role": "assistant",
                        "content": "ê·¸ëŸ¼ ì´ì œ ì§‘ì—ê°€ì„œ ë­í•˜ê²Œ?"
                    },
                    {
                        "role": "user",
                        "content": "ë„·í”Œë¦­ìŠ¤ ë³´ê³  ìì•¼ì§€, ì˜¤ëŠ˜ì€ ê¸°ë¡ ê·¸ë§Œí• ë˜"
                    },
                    {
                        "role": "assistant",
                        "content": "ê·¸ë˜ ì˜ì ì˜¤ëŠ˜ í‘¹ ì‰¬ê³ !"
                    }
                ]
            }
        }
    }


@app.post(
    '/get-summary',
    status_code=status.HTTP_201_CREATED,
    response_model=SummaryModel,
    responses={
        451: {
            "description": "Gpt's Refusal",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Refused by GPT for inappropriate Word use, <refusal body>"
                    }
                }
            }
        },
        500: {
            "description": "Internal Server Error",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Unidentified Errors with Structured Outputs completion : <Exception Code>"
                    }
                }
            }
        }
    }
)
async def getSummaryFromGpt(conversationModel: ConversationModel) -> SummaryModel:
    try:
        completion = await asyncio.to_thread(
            client.beta.chat.completions.parse,
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"{system_prompt}"
                },
                {
                    "role": "user",
                    "content": f"{conversationModel.messages}"
                },
            ],
            response_format=SummaryModel,
        )
        response = completion.choices[0].message

        if response.parsed:
            response_json = response.parsed.model_dump()
            return SummaryModel(
                dotori_emotion=response_json['dotori_emotion'],
                summary=response_json['summary']
            )
        elif response.refusal:
            raise HTTPException(
                status_code=status.HTTP_451_UNAVAILABLE_FOR_LEGAL_REASONS,
                detail=f'Refused by GPT for inappropriate Word use, {response.refusal}'
            )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f'Unidentified Errors with Structured Outputs completion : {e}'
        )


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
